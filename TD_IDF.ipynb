{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e890ad35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize, pos_tag\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords, words\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da92f6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/swastik/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /home/swastik/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to /home/swastik/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package words to /home/swastik/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/words.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('punkt')\n",
    "nltk.download('words')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e11c6f8",
   "metadata": {},
   "source": [
    "## Importing the data\n",
    "This code loops from the folders of TXT and takes every .txt file that does not start with ._ which contain the speeches per country per year. These are then added to a dataframe, storing the year, country code and the speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1e038f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YEM</td>\n",
       "      <td>2013</td>\n",
       "      <td>Allow \\nme, at the outset to extend sincere my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NER</td>\n",
       "      <td>2013</td>\n",
       "      <td>It is a great \\nhonour for me to take the floo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SWZ</td>\n",
       "      <td>2013</td>\n",
       "      <td>It is a great pleasure for me to have \\nthis o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MNG</td>\n",
       "      <td>2013</td>\n",
       "      <td>Allow me to first congratulate \\nMr. John Ashe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SGP</td>\n",
       "      <td>2013</td>\n",
       "      <td>I warmly \\ncongratulate Mr. John Ashe on his e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country  year                                             speech\n",
       "0     YEM  2013  Allow \\nme, at the outset to extend sincere my...\n",
       "1     NER  2013  It is a great \\nhonour for me to take the floo...\n",
       "2     SWZ  2013  It is a great pleasure for me to have \\nthis o...\n",
       "3     MNG  2013  Allow me to first congratulate \\nMr. John Ashe...\n",
       "4     SGP  2013  I warmly \\ncongratulate Mr. John Ashe on his e..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path(\"/home/swastik/Downloads/UNGDC_1946-2024(1)/TXT\")\n",
    "\n",
    "name_text = []\n",
    "for folder in path.iterdir():\n",
    "    if folder.is_dir():\n",
    "        files = [f for f in folder.glob(\"*.txt\") if not f.name.startswith(\"._\")]\n",
    "\n",
    "        for file in files:\n",
    "            name = file.name\n",
    "            text = file.read_text(encoding=\"utf-8\")\n",
    "            \n",
    "            name_text.append({\n",
    "                        \"country\": name[:3],\n",
    "                        \"year\": name[-8:-4],\n",
    "                        \"speech\": text\n",
    "                    })\n",
    "    \n",
    "df = pd.DataFrame(name_text)\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90c6e9fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3283</th>\n",
       "      <td>DEU</td>\n",
       "      <td>2019</td>\n",
       "      <td>Here in New York over the past few days, we ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3284</th>\n",
       "      <td>MKD</td>\n",
       "      <td>2019</td>\n",
       "      <td>My country has been a Member of the United Nat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3285</th>\n",
       "      <td>LAO</td>\n",
       "      <td>2019</td>\n",
       "      <td>At the outset, I would like to congratulate Pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3286</th>\n",
       "      <td>GUY</td>\n",
       "      <td>2019</td>\n",
       "      <td>I bring to President Tijjani Muhammad-Bande fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3287</th>\n",
       "      <td>GRD</td>\n",
       "      <td>2019</td>\n",
       "      <td>I extend cordial greetings from the Government...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     country  year                                             speech\n",
       "3283     DEU  2019  Here in New York over the past few days, we ha...\n",
       "3284     MKD  2019  My country has been a Member of the United Nat...\n",
       "3285     LAO  2019  At the outset, I would like to congratulate Pr...\n",
       "3286     GUY  2019  I bring to President Tijjani Muhammad-Bande fr...\n",
       "3287     GRD  2019  I extend cordial greetings from the Government..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ee99a3",
   "metadata": {},
   "source": [
    "## Punctuation - Stopwords - Tokenizing\n",
    "The following code removes all punctuation from the texts, it also tokenizes the string (returns a list of each word separately as a string) and removes stopwords from it and non alphabetical tokens\n",
    "\n",
    "https://www.geeksforgeeks.org/nlp/removing-stop-words-nltk-python/ \n",
    "\n",
    "https://www.geeksforgeeks.org/python/python-remove-punctuation-from-string/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e120ece",
   "metadata": {},
   "source": [
    "We also remove words that are related to countries as can be found in the CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c04c21c",
   "metadata": {},
   "source": [
    "https://en.wikipedia.org/wiki/List_of_adjectival_and_demonymic_forms_for_countries_and_nations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e9f6d25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_df = pd.read_csv(\"List_of_adjectival_and_demonymic_forms_for_countries_and_nations_1.csv\")\n",
    "countries_flat = countries_df.values.ravel().tolist()\n",
    "countries = []\n",
    "\n",
    "def split_small_capital(text):\n",
    "    split = re.sub(r'([a-z])([A-Z])', r'\\1 \\2', text).split()\n",
    "    countries.extend(split)\n",
    "\n",
    "for country_adj in countries_flat: split_small_capital(country_adj)\n",
    "\n",
    "countries = [country.lower()for country in countries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda82dd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>speech</th>\n",
       "      <th>speech_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YEM</td>\n",
       "      <td>2013</td>\n",
       "      <td>Allow \\nme, at the outset to extend sincere my...</td>\n",
       "      <td>[allow, outset, extend, sincere, ambassador, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NER</td>\n",
       "      <td>2013</td>\n",
       "      <td>It is a great \\nhonour for me to take the floo...</td>\n",
       "      <td>[great, take, floor, session, general, assembl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SWZ</td>\n",
       "      <td>2013</td>\n",
       "      <td>It is a great pleasure for me to have \\nthis o...</td>\n",
       "      <td>[great, pleasure, opportunity, join, fellow, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MNG</td>\n",
       "      <td>2013</td>\n",
       "      <td>Allow me to first congratulate \\nMr. John Ashe...</td>\n",
       "      <td>[allow, first, congratulate, assuming, preside...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SGP</td>\n",
       "      <td>2013</td>\n",
       "      <td>I warmly \\ncongratulate Mr. John Ashe on his e...</td>\n",
       "      <td>[warmly, congratulate, election, president, se...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country  year                                             speech  \\\n",
       "0     YEM  2013  Allow \\nme, at the outset to extend sincere my...   \n",
       "1     NER  2013  It is a great \\nhonour for me to take the floo...   \n",
       "2     SWZ  2013  It is a great pleasure for me to have \\nthis o...   \n",
       "3     MNG  2013  Allow me to first congratulate \\nMr. John Ashe...   \n",
       "4     SGP  2013  I warmly \\ncongratulate Mr. John Ashe on his e...   \n",
       "\n",
       "                                        speech_token  \n",
       "0  [allow, outset, extend, sincere, ambassador, p...  \n",
       "1  [great, take, floor, session, general, assembl...  \n",
       "2  [great, pleasure, opportunity, join, fellow, s...  \n",
       "3  [allow, first, congratulate, assuming, preside...  \n",
       "4  [warmly, congratulate, election, president, se...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "english_vocab = set(words.words())\n",
    "\n",
    "df_tokenize = df.copy()\n",
    "\n",
    "def punc_stop_token_english(speech: str):\n",
    "    # Remove punctuation\n",
    "    speech_no_punctuation = re.sub(r'[^\\w\\s]', '', speech)\n",
    "    \n",
    "    # Tokenize and lowercase\n",
    "    tokens = word_tokenize(speech_no_punctuation.lower())\n",
    "    \n",
    "    # POS tagging\n",
    "    pos_tags = pos_tag(tokens)\n",
    "    \n",
    "    # Keep only words that:\n",
    "    # - are alphabetic\n",
    "    # - are not stopwords\n",
    "    # - are not proper nouns (NNP, NNPS)\n",
    "    # - are in English vocabulary\n",
    "    new_speech = [\n",
    "        word for word, tag in pos_tags\n",
    "        if (word.isalpha()) \n",
    "        and (word not in stop_words)\n",
    "        and (word not in countries)\n",
    "        and (tag not in ['NNP', 'NNPS'])\n",
    "        and (word in english_vocab)\n",
    "    ]\n",
    "    \n",
    "    return new_speech\n",
    "\n",
    "# Apply to your dataframe\n",
    "df_tokenize['speech_token'] = df_tokenize['speech'].apply(punc_stop_token_english)\n",
    "df_tokenize.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "76d29ddb-24f4-455b-b430-5da47f8ce698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 most common bigrams:\n",
      "climate change               8947\n",
      "sustainable development          7608\n",
      "general assembly             7281\n",
      "international community            7275\n",
      "security council              6496\n",
      "peace security             5437\n",
      "per cent                 3957\n",
      "would like                 3841\n",
      "international law                  2820\n",
      "international peace                2012\n",
      "middle east                 1945\n",
      "rule law                  1902\n",
      "let us                   1807\n",
      "small island               1805\n",
      "assembly session              1714\n",
      "charter united               1597\n",
      "millennium development          1553\n",
      "economic social               1551\n",
      "development agenda               1484\n",
      "president general              1394\n"
     ]
    }
   ],
   "source": [
    "# --- Bigram frequency check (after tokenization) ---\n",
    "from collections import Counter\n",
    "from nltk import ngrams\n",
    "\n",
    "all_bigrams = []\n",
    "for tokens in df_tokenize['speech_token']:   # your tokens are in this column\n",
    "    if isinstance(tokens, list):\n",
    "        all_bigrams.extend(list(ngrams(tokens, 2)))\n",
    "\n",
    "bigram_counts = Counter(all_bigrams)\n",
    "\n",
    "print(\"Top 20 most common bigrams:\")\n",
    "for (w1, w2), cnt in bigram_counts.most_common(20):\n",
    "    print(f\"{w1} {w2:<20} {cnt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acee553",
   "metadata": {},
   "source": [
    "## Polarization score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1a929742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>political polarization score (central estimate)</th>\n",
       "      <th>polarization label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>1992</td>\n",
       "      <td>2.775</td>\n",
       "      <td>Polarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>1993</td>\n",
       "      <td>2.775</td>\n",
       "      <td>Polarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>1994</td>\n",
       "      <td>2.775</td>\n",
       "      <td>Polarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>1995</td>\n",
       "      <td>2.775</td>\n",
       "      <td>Polarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>1996</td>\n",
       "      <td>2.775</td>\n",
       "      <td>Polarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22674</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>2020</td>\n",
       "      <td>2.499</td>\n",
       "      <td>Polarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22675</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>2021</td>\n",
       "      <td>2.066</td>\n",
       "      <td>Polarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22676</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>2022</td>\n",
       "      <td>1.551</td>\n",
       "      <td>Polarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22677</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>2023</td>\n",
       "      <td>1.984</td>\n",
       "      <td>Polarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22678</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>2024</td>\n",
       "      <td>1.293</td>\n",
       "      <td>Polarized</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22679 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            entity country  year  \\\n",
       "0      Afghanistan     AFG  1992   \n",
       "1      Afghanistan     AFG  1993   \n",
       "2      Afghanistan     AFG  1994   \n",
       "3      Afghanistan     AFG  1995   \n",
       "4      Afghanistan     AFG  1996   \n",
       "...            ...     ...   ...   \n",
       "22674     Zimbabwe     ZWE  2020   \n",
       "22675     Zimbabwe     ZWE  2021   \n",
       "22676     Zimbabwe     ZWE  2022   \n",
       "22677     Zimbabwe     ZWE  2023   \n",
       "22678     Zimbabwe     ZWE  2024   \n",
       "\n",
       "       political polarization score (central estimate) polarization label  \n",
       "0                                                2.775          Polarized  \n",
       "1                                                2.775          Polarized  \n",
       "2                                                2.775          Polarized  \n",
       "3                                                2.775          Polarized  \n",
       "4                                                2.775          Polarized  \n",
       "...                                                ...                ...  \n",
       "22674                                            2.499          Polarized  \n",
       "22675                                            2.066          Polarized  \n",
       "22676                                            1.551          Polarized  \n",
       "22677                                            1.984          Polarized  \n",
       "22678                                            1.293          Polarized  \n",
       "\n",
       "[22679 rows x 5 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polarization_df = pd.read_csv(\"political-polarization-score.csv\")\n",
    "polarization_df.head()\n",
    "\n",
    "polarization_df.columns = polarization_df.columns.str.lower()\n",
    "\n",
    "bounds = [ -3, -1, 1, 3]\n",
    "\n",
    "labels = [\n",
    "    \"Stable\",\n",
    "    \"Neutral\",\n",
    "    \"Polarized\"\n",
    "]\n",
    "\n",
    "polarization_df[\"polarization label\"] = pd.cut(\n",
    "    polarization_df[\"political polarization score (central estimate)\"],\n",
    "    bins=bounds,\n",
    "    labels=labels,\n",
    "    include_lowest=True,\n",
    "    right=False\n",
    ")\n",
    "polarization_df = polarization_df.rename(columns={\"code\": \"country\"})\n",
    "\n",
    "\n",
    "polarization_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1036e6a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>speech</th>\n",
       "      <th>speech_token</th>\n",
       "      <th>political polarization score (central estimate)</th>\n",
       "      <th>polarization label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AFG</td>\n",
       "      <td>2008</td>\n",
       "      <td>Since the last time we \\ngathered here in this...</td>\n",
       "      <td>[since, last, time, great, hall, year, great, ...</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>AFG</td>\n",
       "      <td>2009</td>\n",
       "      <td>First, I would like to \\ncongratulate His Exce...</td>\n",
       "      <td>[first, would, like, congratulate, excellency,...</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>AFG</td>\n",
       "      <td>2010</td>\n",
       "      <td>I join previous \\nspeakers in congratulating y...</td>\n",
       "      <td>[join, previous, sir, election, president, gen...</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>AFG</td>\n",
       "      <td>2011</td>\n",
       "      <td>I am honoured to be \\nhere to read the stateme...</td>\n",
       "      <td>[read, statement, president, excellency, retur...</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>AFG</td>\n",
       "      <td>2012</td>\n",
       "      <td>﻿As we speak today, the world\\nis being shaken...</td>\n",
       "      <td>[speak, today, world, shaken, depravity, insul...</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22674</th>\n",
       "      <td>ZWE</td>\n",
       "      <td>2020</td>\n",
       "      <td>Your Excellency, Ambassador Volkan Bozkir, Pre...</td>\n",
       "      <td>[excellency, ambassador, president, session, u...</td>\n",
       "      <td>2.499</td>\n",
       "      <td>Polarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22675</th>\n",
       "      <td>ZWE</td>\n",
       "      <td>2021</td>\n",
       "      <td>Your Excellency Abdulla Shahid, President of t...</td>\n",
       "      <td>[excellency, president, session, general, asse...</td>\n",
       "      <td>2.066</td>\n",
       "      <td>Polarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22676</th>\n",
       "      <td>ZWE</td>\n",
       "      <td>2022</td>\n",
       "      <td>It is my singular honour to deliver this state...</td>\n",
       "      <td>[singular, deliver, statement, assembly, allow...</td>\n",
       "      <td>1.551</td>\n",
       "      <td>Polarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22677</th>\n",
       "      <td>ZWE</td>\n",
       "      <td>2023</td>\n",
       "      <td>I wish to congratulate Mr. Dennis Francis on h...</td>\n",
       "      <td>[wish, congratulate, election, president, gene...</td>\n",
       "      <td>1.984</td>\n",
       "      <td>Polarized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22678</th>\n",
       "      <td>ZWE</td>\n",
       "      <td>2024</td>\n",
       "      <td>Your Excellency, Mr. Philemon Yang, President ...</td>\n",
       "      <td>[excellency, president, session, general, asse...</td>\n",
       "      <td>1.293</td>\n",
       "      <td>Polarized</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2802 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      country  year                                             speech  \\\n",
       "16        AFG  2008  Since the last time we \\ngathered here in this...   \n",
       "17        AFG  2009  First, I would like to \\ncongratulate His Exce...   \n",
       "18        AFG  2010  I join previous \\nspeakers in congratulating y...   \n",
       "19        AFG  2011  I am honoured to be \\nhere to read the stateme...   \n",
       "20        AFG  2012  ﻿As we speak today, the world\\nis being shaken...   \n",
       "...       ...   ...                                                ...   \n",
       "22674     ZWE  2020  Your Excellency, Ambassador Volkan Bozkir, Pre...   \n",
       "22675     ZWE  2021  Your Excellency Abdulla Shahid, President of t...   \n",
       "22676     ZWE  2022  It is my singular honour to deliver this state...   \n",
       "22677     ZWE  2023  I wish to congratulate Mr. Dennis Francis on h...   \n",
       "22678     ZWE  2024  Your Excellency, Mr. Philemon Yang, President ...   \n",
       "\n",
       "                                            speech_token  \\\n",
       "16     [since, last, time, great, hall, year, great, ...   \n",
       "17     [first, would, like, congratulate, excellency,...   \n",
       "18     [join, previous, sir, election, president, gen...   \n",
       "19     [read, statement, president, excellency, retur...   \n",
       "20     [speak, today, world, shaken, depravity, insul...   \n",
       "...                                                  ...   \n",
       "22674  [excellency, ambassador, president, session, u...   \n",
       "22675  [excellency, president, session, general, asse...   \n",
       "22676  [singular, deliver, statement, assembly, allow...   \n",
       "22677  [wish, congratulate, election, president, gene...   \n",
       "22678  [excellency, president, session, general, asse...   \n",
       "\n",
       "       political polarization score (central estimate) polarization label  \n",
       "16                                              -0.014            Neutral  \n",
       "17                                              -0.014            Neutral  \n",
       "18                                              -0.014            Neutral  \n",
       "19                                              -0.014            Neutral  \n",
       "20                                              -0.014            Neutral  \n",
       "...                                                ...                ...  \n",
       "22674                                            2.499          Polarized  \n",
       "22675                                            2.066          Polarized  \n",
       "22676                                            1.551          Polarized  \n",
       "22677                                            1.984          Polarized  \n",
       "22678                                            1.293          Polarized  \n",
       "\n",
       "[2802 rows x 6 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for df in (df_tokenize, polarization_df):\n",
    "    df['country'] = df['country'].astype(str).str.strip()\n",
    "    df['year'] = pd.to_numeric(df['year'], errors='coerce').astype('Int64')\n",
    "\n",
    "bad_tf = df_tokenize[df_tokenize['year'].isna()]\n",
    "bad_pol = polarization_df[polarization_df['year'].isna()]\n",
    "\n",
    "merged_df = df_tokenize.merge(\n",
    "    polarization_df,\n",
    "    how='right',\n",
    "    on=['country', 'year']\n",
    ")\n",
    "merged_df = merged_df.drop(columns=['entity'])\n",
    "merged_df = merged_df.dropna()\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381a45dd",
   "metadata": {},
   "source": [
    "## TF-IDF\n",
    "The following code calculates the TF-IDF score for each word in every speech, this is then stored in the Dataframe as a list of pairs, containing (word, tf-idf score), sorted descendingly, so you get the higher TF-IDF scores first\n",
    "\n",
    "https://www.geeksforgeeks.org/machine-learning/understanding-tf-idf-term-frequency-inverse-document-frequency/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e0feb2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tf_idf = merged_df.copy()\n",
    "\n",
    "df_tf_idf['speech_token'] = df_tf_idf['speech_token'].str.join(' ')\n",
    "\n",
    "tfidf_vector = TfidfVectorizer()\n",
    "speeches = df_tf_idf['speech_token']\n",
    "\n",
    "tf_idf_matrix  = tfidf_vector.fit_transform(speeches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ba1af3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 1266635 stored elements and shape (2802, 15581)>\n",
      "  Coords\tValues\n",
      "  (0, 12434)\t0.03989089265430518\n",
      "  (0, 7753)\t0.09191268839713386\n",
      "  (0, 13821)\t0.03229353297424898\n",
      "  (0, 5997)\t0.059467195739140166\n",
      "  (0, 6114)\t0.0388121467370732\n",
      "  (0, 15535)\t0.052166142284736414\n",
      "  (0, 5989)\t0.04020515057982752\n",
      "  (0, 5893)\t0.0859414606539855\n",
      "  (0, 6461)\t0.015512633609364748\n",
      "  (0, 121)\t0.07095328379300604\n",
      "  (0, 13037)\t0.05618339681318859\n",
      "  (0, 6451)\t0.05313908805478291\n",
      "  (0, 818)\t0.07544678866583744\n",
      "  (0, 15464)\t0.08300388692301199\n",
      "  (0, 6047)\t0.09158624974780905\n",
      "  (0, 5884)\t0.029770658816654014\n",
      "  (0, 14423)\t0.03270752445871978\n",
      "  (0, 2254)\t0.01707842060852194\n",
      "  (0, 2068)\t0.016076773209113465\n",
      "  (0, 11292)\t0.02711690194352751\n",
      "  (0, 12099)\t0.0616683981782035\n",
      "  (0, 8520)\t0.09083799344966703\n",
      "  (0, 12329)\t0.12916354002124258\n",
      "  (0, 5456)\t0.05027524356593249\n",
      "  (0, 8227)\t0.05119771275913079\n",
      "  :\t:\n",
      "  (2801, 2778)\t0.05409247272048699\n",
      "  (2801, 921)\t0.03897610554135286\n",
      "  (2801, 9196)\t0.043687482936947006\n",
      "  (2801, 8221)\t0.06068556959679126\n",
      "  (2801, 10694)\t0.048486994864396366\n",
      "  (2801, 1348)\t0.05685211223984807\n",
      "  (2801, 3675)\t0.1402823766235987\n",
      "  (2801, 13789)\t0.11145126649670464\n",
      "  (2801, 4497)\t0.05193486713027442\n",
      "  (2801, 6934)\t0.11451575986623044\n",
      "  (2801, 9186)\t0.07103754630443304\n",
      "  (2801, 6962)\t0.05725787993311522\n",
      "  (2801, 9657)\t0.05079108625770086\n",
      "  (2801, 6341)\t0.060117419068939484\n",
      "  (2801, 14353)\t0.06335209435400671\n",
      "  (2801, 936)\t0.05858517238417659\n",
      "  (2801, 10262)\t0.05768091944335977\n",
      "  (2801, 14869)\t0.059070143111398965\n",
      "  (2801, 14837)\t0.11624553354064325\n",
      "  (2801, 13086)\t0.058122766770321625\n",
      "  (2801, 13018)\t0.061929682247223235\n",
      "  (2801, 11689)\t0.05858517238417659\n",
      "  (2801, 7916)\t0.06950529961967013\n",
      "  (2801, 3685)\t0.06700725225459839\n",
      "  (2801, 9585)\t0.08195767353992657\n"
     ]
    }
   ],
   "source": [
    "print(tf_idf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "33594f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = tfidf_vector.get_feature_names_out()\n",
    "\n",
    "def matrix_to_tfidf_pairs(row):\n",
    "    row_array = row.toarray().flatten()  \n",
    "    word_tf_idf_pairs = [(word, score) for word, score in zip(feature_names, row_array) if score > 0]\n",
    "    pairs_sorted = sorted(word_tf_idf_pairs, key=lambda x: x[1], reverse=True)\n",
    "    return pairs_sorted\n",
    "\n",
    "df_tf_idf['speech_score'] = [matrix_to_tfidf_pairs(tf_idf_matrix[i]) for i in range(tf_idf_matrix.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "da1aace9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>speech_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AFG</td>\n",
       "      <td>2008</td>\n",
       "      <td>[(terrorism, 0.19712251036538642), (developmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>AFG</td>\n",
       "      <td>2009</td>\n",
       "      <td>[(intellectual, 0.19534902855967673), (interna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>AFG</td>\n",
       "      <td>2010</td>\n",
       "      <td>[(jirga, 0.34036720227934886), (people, 0.1781...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>AFG</td>\n",
       "      <td>2011</td>\n",
       "      <td>[(transition, 0.21339185483483689), (internati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>AFG</td>\n",
       "      <td>2012</td>\n",
       "      <td>[(peace, 0.20130430468300325), (security, 0.20...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country  year                                       speech_score\n",
       "16     AFG  2008  [(terrorism, 0.19712251036538642), (developmen...\n",
       "17     AFG  2009  [(intellectual, 0.19534902855967673), (interna...\n",
       "18     AFG  2010  [(jirga, 0.34036720227934886), (people, 0.1781...\n",
       "19     AFG  2011  [(transition, 0.21339185483483689), (internati...\n",
       "20     AFG  2012  [(peace, 0.20130430468300325), (security, 0.20..."
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tf_idf[['country', 'year', 'speech_score']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8054ab9-7d11-49ff-afce-20f47a374d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs: 2802 Vocab size (with bigrams): 314704\n"
     ]
    }
   ],
   "source": [
    "# --- TF-IDF with unigrams + bigrams (n-grams) ---\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# use the same joined text you created above\n",
    "texts = df_tf_idf['speech']  # already ' '.join(tokens)\n",
    "\n",
    "tfidf_ngram = TfidfVectorizer(\n",
    "    lowercase=True,\n",
    "    token_pattern=r\"(?u)\\b\\w+\\b\",  # keep words and numbers\n",
    "    ngram_range=(1, 2),            # unigrams + bigrams\n",
    "    min_df=2,\n",
    "    max_df=0.9,\n",
    ")\n",
    "\n",
    "tf_idf_matrix_ngram = tfidf_ngram.fit_transform(texts)\n",
    "feature_names_ngram = tfidf_ngram.get_feature_names_out()\n",
    "\n",
    "print(\"Docs:\", tf_idf_matrix_ngram.shape[0],\n",
    "      \"Vocab size (with bigrams):\", tf_idf_matrix_ngram.shape[1])\n",
    "\n",
    "def matrix_to_tfidf_pairs_ng(row):\n",
    "    arr = row.toarray().flatten()\n",
    "    pairs = [(w, s) for w, s in zip(feature_names_ngram, arr) if s > 0]\n",
    "    return sorted(pairs, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# store bigram-aware scores in a NEW column, while keeping original intact\n",
    "df_tf_idf['speech_score_bigrams'] = [\n",
    "    matrix_to_tfidf_pairs_ng(tf_idf_matrix_ngram[i])\n",
    "    for i in range(tf_idf_matrix_ngram.shape[0])\n",
    "]\n",
    "\n",
    "# quick peek into the dataframe with speech score for both unigrams AND bigrams\n",
    "df_tf_idf[['country', 'year', 'speech_score_bigrams']].tail()\n",
    "df_tf_idf[['country', 'year', 'speech_score_bigrams']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7822c2",
   "metadata": {},
   "source": [
    "## Linear Regression - Lasso\n",
    "\n",
    "https://scikit-learn.org/stable/modules/linear_model.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08cde2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9832a421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.09115565348494908\n",
      "Mean Absolute Error: 0.2446033237264886\n",
      "R^2 Score: 0.5249242772266041\n"
     ]
    }
   ],
   "source": [
    "df_lin = merged_df.copy()\n",
    "df_lin = df_lin.rename(columns={\"political polarization score (central estimate)\": \"polarization score\"})\n",
    "\n",
    "y = np.array(df_lin[\"polarization score\"]).reshape(-1, 1)\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "y_scaled = scaler.fit_transform(y)\n",
    "\n",
    "df_lin[\"polarization scaled\"] = y_scaled\n",
    "\n",
    "\n",
    "X = tf_idf_matrix\n",
    "y = df_lin['polarization scaled']\n",
    "# y = df_lin['polarization score']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model_lin = linear_model.Ridge(alpha=0.1)\n",
    "model_lin.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model_lin.predict(X_test)\n",
    "\n",
    "MSE = mean_squared_error(y_test, y_pred)\n",
    "MAE = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", MSE)\n",
    "print(\"Mean Absolute Error:\", MAE)\n",
    "print(\"R^2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd71bdf8",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b24ee89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2b1ec75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/swastik/anaconda3/lib/python3.13/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6185383244206774\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.55      0.94      0.70       260\n",
      "   Polarized       0.76      0.21      0.33       152\n",
      "      Stable       0.90      0.48      0.62       149\n",
      "\n",
      "    accuracy                           0.62       561\n",
      "   macro avg       0.74      0.54      0.55       561\n",
      "weighted avg       0.70      0.62      0.58       561\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = tf_idf_matrix\n",
    "y = merged_df['polarization label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
